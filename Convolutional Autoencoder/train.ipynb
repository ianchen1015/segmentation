{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/tkuanlun350/Tensorflow-SegNet/blob/master/model.py\n",
    "https://ithelp.ithome.com.tw/articles/10188326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pythpm :  3.6.4 (v3.6.4:d48ecebad5, Dec 18 2017, 21:07:28) \n",
      "[GCC 4.2.1 (Apple Inc. build 5666) (dot 3)]\n",
      "tensorflow :  1.7.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "\n",
    "print('pythpm : ',sys.version)\n",
    "print('tensorflow : ',tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paremeters\n",
    "img_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 256\n",
    "# load training data\n",
    "def next_batch(batch_size):\n",
    "    filenames = []\n",
    "    for root, dirs, files in os.walk('./data/x'):\n",
    "        for name in files:\n",
    "            filenames.append(os.path.join(root, name).split('/')[-1])\n",
    "\n",
    "    data_shape = (batch_size, img_size, img_size)\n",
    "    X = np.zeros(data_shape)\n",
    "    Y = np.zeros(data_shape)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        f = random.choice(filenames)\n",
    "        img = np.array(cv2.imread('./data/x/' + f, 0))\n",
    "        img2 = np.array(cv2.imread('./data/y/' + f, 0))\n",
    "        X[i, :, :] = img\n",
    "        Y[i, :, :] = img2\n",
    "    \n",
    "    X = X.reshape(batch_size, img_size*img_size)\n",
    "    Y = Y.reshape(batch_size, img_size*img_size)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape, name):\n",
    "    initial = tf.truncated_normal(shape, stddev = 0.1)\n",
    "    return tf.Variable(initial, name)\n",
    "\n",
    "def bias_variable(shape, name):\n",
    "    initial = tf.constant(0.1, shape = shape)\n",
    "    return tf.Variable(initial, name)\n",
    "'''\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding = 'SAME')\n",
    "'''\n",
    "\n",
    "def conv2d_layer(x, W_shape, b_shape, name, padding='SAME'):\n",
    "    W = weight_variable(W_shape, name+'_W')\n",
    "    b = bias_variable([b_shape], name+'_b')\n",
    "    return tf.nn.relu(tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding=padding) + b)\n",
    "'''\n",
    "def deconv2d_(x, W, output_shape):\n",
    "    return tf.nn.conv2d_transpose(x, W, output_shape, strides = [1, 1, 1, 1], padding = 'SAME')\n",
    " '''   \n",
    "def deconv_layer(x, W_shape, b_shape, name, padding='SAME'):\n",
    "    W = weight_variable(W_shape, name+'_W')\n",
    "    b = bias_variable([b_shape], name+'_b')\n",
    "    x_shape = tf.shape(x)\n",
    "    out_shape = tf.stack([x_shape[0], x_shape[1], x_shape[2], W_shape[2]])\n",
    "    return tf.nn.conv2d_transpose(x, W, out_shape, [1, 1, 1, 1], padding=padding) + b\n",
    "\n",
    "def max_pool_2x2_layer(x):\n",
    "    #_, argmax = tf.nn.max_pool_with_argmax(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding = 'SAME')\n",
    "    pool = tf.nn.max_pool(x, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "    return pool\n",
    "\n",
    "def max_unpool_2x2_layer(x, shape): # input shape\n",
    "    inference = tf.image.resize_nearest_neighbor(x, tf.stack([shape[1]*2, shape[2]*2]))\n",
    "    return inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input layer shape : (?, 256, 256, 1)\n",
      "code layer shape : (?, 32, 32, 256)\n",
      "output layer shape : (?, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape = [None, 256*256], name='x')\n",
    "y = tf.placeholder(tf.float32, shape = [None, 256*256], name='y')\n",
    "x_origin = tf.reshape(x, [-1, 256, 256, 1])\n",
    "y_origin = tf.reshape(y, [-1, 256, 256, 1])\n",
    "\n",
    "# conv1 256\n",
    "conv_1_1 = conv2d_layer(x_origin, [5, 5, 1, 64], 64, \"conv_1_1\", padding='SAME')\n",
    "conv_1_2 = conv2d_layer(conv_1_1, [5, 5, 64, 64], 64, \"conv_1_2\", padding='SAME')\n",
    "# pool1 256 > 128\n",
    "pool_1 = max_pool_2x2_layer(conv_1_2)\n",
    "\n",
    "# conv2 128\n",
    "conv_2_1 = conv2d_layer(pool_1, [5, 5, 64, 128], 128, \"conv_2_1\", padding='SAME')\n",
    "conv_2_2 = conv2d_layer(conv_2_1, [5, 5, 128, 128], 128, \"conv_2_2\", padding='SAME')\n",
    "# pool2 128> 64\n",
    "pool_2 = max_pool_2x2_layer(conv_2_2)\n",
    "\n",
    "# conv3 64\n",
    "conv_3_1 = conv2d_layer(pool_2, [5, 5, 128, 256], 256, \"conv_3_1\", padding='SAME')\n",
    "conv_3_2 = conv2d_layer(conv_3_1, [5, 5, 256, 256], 256, \"conv_3_2\", padding='SAME')\n",
    "# pool3 64 > 32\n",
    "pool_3 = max_pool_2x2_layer(conv_3_2)\n",
    "\n",
    "'''\n",
    "# conv4 32\n",
    "conv_4_1 = conv2d_layer(pool_3, [5, 5, 256, 512], 512, \"conv_4_1\", padding='SAME')\n",
    "conv_4_2 = conv2d_layer(conv_4_1, [5, 5, 512, 512], 512, \"conv_4_2\", padding='SAME')\n",
    "# pool4 32 > 16\n",
    "pool_4 = max_pool_2x2_layer(conv_4_2)\n",
    "\n",
    "'''\n",
    "# code 16,512\n",
    "code_layer = pool_3\n",
    "\n",
    "'''\n",
    "# deconv4 16\n",
    "deconv_4_2 = deconv_layer(code_layer, [5, 5, 512, 512], 512, 'deconv_4_2', padding='SAME')\n",
    "deconv_4_1 = deconv_layer(deconv_4_2, [5, 5, 256, 512], 256, 'deconv_4_1', padding='SAME')\n",
    "# unpool4 16 > 32\n",
    "unpool_4 = max_unpool_2x2_layer(deconv_4_1, [-1, 16, 16, 256]) \n",
    "'''\n",
    "\n",
    "# deconv3 32\n",
    "deconv_3_2 = deconv_layer(code_layer, [5, 5, 256, 256], 256, 'deconv_3_2', padding='SAME')\n",
    "deconv_3_1 = deconv_layer(deconv_3_2, [5, 5, 128, 256], 128, 'deconv_3_1', padding='SAME')\n",
    "# unpool3 32 > 64\n",
    "unpool_3 = max_unpool_2x2_layer(deconv_3_1, [-1, 32, 32, 128])    \n",
    "\n",
    "# deconv2 64\n",
    "deconv_2_2 = deconv_layer(unpool_3, [5, 5, 128, 128], 128, 'deconv_2_2', padding='SAME')\n",
    "deconv_2_1 = deconv_layer(deconv_2_2, [5, 5, 64, 128], 64, 'deconv_2_1', padding='SAME')\n",
    "# unpool2 64 > 128\n",
    "unpool_2 = max_unpool_2x2_layer(deconv_2_1, [-1, 64, 64, 64])\n",
    "\n",
    "# deconv1 128\n",
    "deconv_1_2 = deconv_layer(unpool_2, [5, 5, 64, 64], 64, 'deconv_1_2', padding='SAME')\n",
    "deconv_1_1 = deconv_layer(deconv_1_2, [5, 5, 1, 64], 1, 'deconv_1_1', padding='SAME')\n",
    "# unpool1 128 > 256\n",
    "unpool_1 = max_unpool_2x2_layer(deconv_1_1, [-1, 128, 128, 1])\n",
    "\n",
    "x_reconstruct = unpool_1\n",
    "\n",
    "result = tf.sigmoid(x_reconstruct, name='result')\n",
    "result_round = tf.round(x_reconstruct, name='result_round')\n",
    "\n",
    "print(\"input layer shape : %s\" % x_origin.get_shape())\n",
    "print(\"code layer shape : %s\" % code_layer.get_shape())\n",
    "print(\"output layer shape : %s\" % result.get_shape())\n",
    "\n",
    "# optimizer\n",
    "with tf.name_scope('loss'):\n",
    "    #cost = tf.reduce_mean(tf.pow(y_origin - result, 2))\n",
    "    cost = tf.sqrt(tf.reduce_mean(tf.square(y_origin - result)))\n",
    "    tf.summary.scalar('loss', cost)\n",
    "optimizer = tf.train.AdamOptimizer(1e-4).minimize(cost)\n",
    "\n",
    "with tf.name_scope('accuracy'):\n",
    "    argmax_probs = tf.round(result)  # 0x1\n",
    "    correct_pred = tf.cast(tf.equal(argmax_probs, y_origin), tf.float32)\n",
    "    accuracy = tf.reduce_mean(correct_pred)\n",
    "    tf.summary.scalar('accuracy', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-bb84db9f1bd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# loss logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# print loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# GPU config\n",
    "#gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "#config = tf.ConfigProto(gpu_options=gpu_options)\n",
    "\n",
    "#sess = tf.Session(config = config)\n",
    "#sess = tf.InteractiveSession()\n",
    "w1 = tf.placeholder(\"float\", name=\"w1\")\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # logs\n",
    "    merged = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(\"logs/\", sess.graph)\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # saver\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    for i in range(5000):\n",
    "        batch_x, batch_y = next_batch(batch_size)\n",
    "        if i%50 == 0: # loss logs\n",
    "            rs = sess.run(merged,feed_dict={x:batch_x, y:batch_y})\n",
    "            writer.add_summary(rs, i)\n",
    "        if i%100 == 0: # print loss\n",
    "            print(\"step %d, loss %g, accuracy %g\"%(i, cost.eval(feed_dict={x:batch_x, y:batch_y}), accuracy.eval(feed_dict={x:batch_x, y:batch_y})))\n",
    "        if (i+1)%1000 == 0: # save\n",
    "            saver.save(sess, 'save/model.ckpt')\n",
    "            print('model saved')\n",
    "\n",
    "        optimizer.run(feed_dict={x:batch_x, y:batch_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
